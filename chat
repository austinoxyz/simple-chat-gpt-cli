#!/usr/bin/python3

# Refererence URL
# https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb

# Example of an OpenAI ChatCompletion request with stream=True
# https://platform.openai.com/docs/guides/chat': '

import sys
import time
import json
import subprocess

import openai

model = 'gpt-3.5-turbo'
api_key_file_name = "./openai_key_file"
openai.api_key_path = api_key_file_name
total_token_usage = { }

RED = '\033[31m'
GREEN = '\033[32m'
YELLOW = '\033[33m'
BLUE = '\033[34m'
RESET = '\033[0m'

def write_colored_output(output, color, end='\n'):
    sys.stdout.write(color + output + RESET + end)

def set_clipboard_text(text):
    p = subprocess.Popen(['xclip', '-selection', 'clipboard'], stdin=subprocess.PIPE)
    p.stdin.write(text.encode('utf-8'))
    p.stdin.close()
    p.wait()


def append_user_message(message):
    global messages
    messages.append({"role": "user", "content": message})

def append_assistant_message(message):
    global messages
    messages.append({"role": "assistant", "content": message})



def load_config(config_file_name):
    # read config file
    try:
        json_raw = ''
        with open(config_file_name, 'r') as config_file:
            json_raw += config_file.read()
        config_raw = json.loads(json_raw)
    except IOError:
        print(f"Couldn't read {config_file_name}. Wheres your config?")
        sys.exit(1)
    except JSONDecodeError:
        print(f"Malformed json in {config_file_name}:")
        import traceback
        print(traceback.format_exc())

    # read api key
    try:
        api_key_file_name = config_raw["api_key_file"]
        with open(api_key_file_name, 'r') as api_key_file:
            key = api_key_file.readline()
    except IOError:
        print(f"Couldn't read {api_key_file_name}. Check your config!")
        sys.exit(1)

    # read token usage
    try:
        token_usage_file_name = config_raw["token_usage_file"]
        with open(token_usage_file_name, 'r') as token_usage_file:
            token_usage = json.loads(token_usage_file.readline())
    except IOError:
        print(f"Couldn't read {token_usage_file_name}. Check your config!")
        sys.exit(1)

    config["api_key"] = key
    return config, token_usage







def account_token_usage(request_token_usage):
    global total_token_usage
    total_token_usage["completion_tokens"] += request_token_usage["completion_tokens"]
    total_token_usage["prompt_tokens"] += 0 # request_token_usage["prompt_tokens"]
    total_token_usage["total_tokens"] += request_token_usage["completion_tokens"] # request_token_usage["total_tokens"]



def print_keys(my_dict):
    print("keys:")
    for key in my_dict.keys():
        print(key)





config = {}
config_file_name = 'config.json'

config, total_token_usage = load_config(config_file_name )
session_token_usage = { "completion_tokens": 0, "prompt_tokens": 0, "total_tokens": 0 }

prompt = "After being given a google search query, you will provide raw markdown that resembles the first 5 results. If provided a number, give the url of that search result."
messages = [{"role": "system", "content": prompt}]

last_response = ''

print('Welcome to gpt-3.5 cli')
print('type `exit` to exit')
while True:
    write_colored_output("> ", YELLOW, end='')
    message = input()

    # TODO implement `save`, `personality new`, `personality load`, `clip`
    if message == 'exit':
        break
    elif message == 'clip':
        if last_response is None:
            print('Must provide an initial message before you can `clip`')
            continue
        set_clipboard_text(last_response)
        continue

    append_user_message(message)

    start_time = time.time()
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=0,
        stream=True
    )

    collected_chunks = []
    collected_messages = []

    chunk_tokens = 0
    for chunk in response:
#        print_keys(chunk)

        chunk_time = time.time() - start_time  # calculate the time delay of the chunk
        collected_chunks.append(chunk)  # save the event response
        chunk_delta = json.loads(f"{chunk['choices'][0]['delta']}")
#        print_keys(chunk_delta)

        chunk_tokens = 0

        if "role" in chunk_delta:
            continue
        elif "content" in chunk_delta:
            chunk_message = chunk_delta["content"]
            collected_messages.append(chunk_message)  # save the message
            chunk_tokens += 1
            print(chunk_message, end='', flush=True)
        last_response = ''.join(collected_messages)
    
    append_assistant_message(message)
    session_token_usage["completion_tokens"] += chunk_tokens
    print()
account_token_usage(session_token_usage)

#session_total_tokens = session_token_usage["total_tokens"]
#print(f'\nConversation ended.\nTotal token usage:\n{ session_total_tokens }')

