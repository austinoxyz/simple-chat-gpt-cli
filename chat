#!/usr/bin/python3

# Refererence URL
# https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb

# Example of an OpenAI ChatCompletion request with stream=True
# https://platform.openai.com/docs/guides/chat': '

import os
import sys
import subprocess
from pathlib import Path
import time
import json
from shutil import get_terminal_size
from typing import List

import openai

APP_NAME = 'simple-chat'

DEFAULT_MODEL = 'gpt-3.5-turbo'

# ansi color sequences
RED = '\033[31m'
GREEN = '\033[32m'
YELLOW = '\033[33m'
BLUE = '\033[34m'

# store terminal width for text justification
TERM_WIDTH = get_terminal_size().columns
if TERM_WIDTH > 120:
    TERM_WIDTH = 120
if TERM_WIDTH < 40:
    TERM_WIDTH = 40

# write ansi colored terminal output
def write_colored_output(output, color, end='\n') -> None:
    sys.stdout.write(color + output + '\033[0m' + end)

def hex_to_truecolor_ansi(color) -> str:
    r = int(color[1:3], base=16)
    g = int(color[3:5], base=16)
    b = int(color[5:7], base=16)
    return f"\x1b[38;2;{r};{g};{b}m"

def truecolor_ify(string_to_print, color) -> str:
    return hex_to_truecolor_ansi(color) + string_to_print + '\x1b[0m'

# write truecolor ansi colored terminal output
def write_truecolor_output(output, color, end='\n') -> None:
    sys.stdout.write(hex_to_truecolor_ansi(color) + output + '\x1b[0m' + end)



# use xclip to put the last chat completion in the clipboard
def set_clipboard_text(text) -> None:
    p = subprocess.Popen(['xclip', '-selection', 'clipboard'], stdin=subprocess.PIPE)
    p.stdin.write(text.encode('utf-8'))
    p.stdin.close()
    p.wait()



## XDG stuff
def get_config_dir() -> str:
    config_dir = os.getenv('XDG_CONFIG_HOME', '')
    if config_dir == '' or config_dir[0] != '/':
        return str(Path.home().joinpath('.config', APP_NAME))
    return str(Path(config_dir).joinpath(APP_NAME))

def get_data_dir() -> str:
    data_dir = os.getenv('XDG_DATA_HOME', '')
    if data_dir == '' or data_dir[0] != '/':
        return str(Path.home().joinpath('.local/share', APP_NAME))
    return str(Path(data_dir).joinpath(APP_NAME))




def append_user_message(message):
    global messages
    messages.append({"role": "user", "content": message})

def append_assistant_message(message):
    global messages
    messages.append({"role": "assistant", "content": message})




def load_prompt_names(prompts_dir) -> List[str]:
    return [filename[:-7] for filename in os.listdir(prompts_dir) if filename.endswith('.prompt')]

def load_prompt(prompt_name, prompts_dir) -> str:
    prompt_file_name = prompt_name + '.prompt'
    prompt_path = os.path.join(prompts_dir, prompt_file_name)
    try:
        with open(prompt_path, 'r') as prompt_file:
            prompt = prompt_file.read()
    except IOError:
        print(f"Couldn't read {prompt_path}. Check your prompts_dir!")
        sys.exit(1)
    print(f'Loaded prompt at {prompt_path}')
    return prompt

def save_prompt(prompt, prompt_name, prompts_dir) -> None:
    prompt_file_name = prompt_name + '.prompt'
    prompt_path = os.path.join(prompts_dir, prompt_file_name)
    print(f'Saving to {prompt_path}')
    try:
        with open(prompt_path, 'w') as prompt_file:
            prompt_file.write(prompt)
    except IOError:
        print(f"Couldn't write to {prompt_path}.")





def load_config(config_file_name):
    try:
        json_raw = ''
        with open(config_file_name, 'r') as config_file:
            json_raw += config_file.read()
        config = json.loads(json_raw)
    except IOError:
        print(f"Couldn't read {config_file_name}. Wheres your config?")
        sys.exit(1)
    except JSONDecodeError:
        print(f"Malformed json in {config_file_name}:")
        import traceback
        print(traceback.format_exc())
    return config

def load_api_key(api_key_file_name) -> str:
    try:
        with open(api_key_file_name, 'r') as api_key_file:
            key = api_key_file.readline()
    except IOError:
        print(f"Couldn't read {api_key_file_name}. Check your config!")
        sys.exit(1)
    return key

def load_token_usage(token_usage_file_name):
    try:
        with open(token_usage_file_name, 'r') as token_usage_file:
            token_usage = json.loads(token_usage_file.readline())
    except IOError:
        print(f"Couldn't read {token_usage_file_name}. Check your config!")
        sys.exit(1)
    return token_usage

def account_token_usage(request_token_usage) -> None:
    pass





config_file_name = 'config.json'
config = load_config(get_config_dir() + '/config.json')

openai.api_key_path = config["api_key_file"]

model = DEFAULT_MODEL
if "model" in config:
    model = config["model"]

token_usage = load_token_usage(get_data_dir() + '/token_usage.json')
session_token_usage = { "completion_tokens": 0, "prompt_tokens": 0, "total_tokens": 0 }

prompt = "After being given a google search query, you will provide raw markdown that resembles the first 5 results. If provided a number, give the url of that search result."
prompt_names = load_prompt_names(get_data_dir() + '/prompts/')


def list_saved_prompts() -> None:
    for i, name in enumerate(prompt_names):
        print(f"\t{i+1}. {name}")

# TODO write custom `center`, `ljust`, and `rjust` functions that ignore truecolor ansi color codes

def print_startup_message() -> None:
    print('\tWelcome to simple-chat-gpt-cli')
    print(f"\ttype {truecolor_ify('exit', config['colors']['blue'])} to exit, or \
{truecolor_ify('help', config['colors']['blue'])} for a list of commands")
    #    print('Welcome to simple-chat-gpt-cli'.center(TERM_WIDTH))
    #    print(f"type {truecolor_ify('exit', config['colors']['blue'])} to exit, or \
    #{truecolor_ify('help', config['colors']['blue'])} for a list of commands".center(TERM_WIDTH))

commands = ['exit', 'clip', 'prompt new', 'prompt list', 'prompt load']
command_usages = ['exit simple-chat-gpt-cli', 
                  'store the contents of the last chat completion in the clipboard', 
                  'create a new prompt and begin using it.', 
                  f"list the saved prompts located in your truecolor_ify(prompts_dir, config['colors']['green']",
                  "load a saved prompt from your truecolor_ify(prompts_dir, config['colors']['green']"]

def print_command_usage(command_name, usage_info):
    print('\t', end='')
    write_truecolor_output(command_name, config["colors"]["blue"], end='')
    print(f": {usage_info}")

def print_commands() -> None:
    print("Commands:")
    print_command_usage('exit', 'exit simple-chat-gpt-cli')
    print_command_usage('clip', 'store the contents of the last chat completion in the clipboard')
    print_command_usage('prompt new', 'create a new prompt and begin using it.')
    print_command_usage('prompt list', 'list the saved prompts located in your `prompts_dir`')
    print_command_usage('prompt load', 'load a saved prompt from your `prompts_dir`')

print_startup_message()

last_response = ''
while True:
    messages = []
    while True:
        write_truecolor_output("> ", config["colors"]["yellow"], end='')
        message = input()

        # TODO implement `help`, 
        # TODO implement `save`, 
        # TODO implement `prompt new`, `prompt load`, `prompt list`
        # TODO implement `personality new`, `personality load` 
        # TODO implement `clip code [n]`
        if message == 'exit':
            account_token_usage(session_token_usage)
            sys.exit(0)
        elif message == 'help':
            print_commands()
            continue
        elif message == 'clip':
            if last_response is None:
                print('Must provide an initial message before you can `clip`')
                continue
            set_clipboard_text(last_response)
            continue
        elif message == 'prompt new':
            if last_response != '':
                print('Are you sure you want to leave the current personality? y/n')
                write_colored_output("> ", YELLOW, end='')
                are_you_sure = input()
                if are_you_sure != 'y':
                    continue
                messages = []
            print('Enter your prompt: ')
            write_colored_output("> ", YELLOW, end='')
            prompt = input()
            print('Would you like to save this prompt for future use?')
            write_colored_output("> ", YELLOW, end='')
            are_you_sure = input()
            if are_you_sure == 'y':
                while True:
                    print('What would you like to name this prompt?')
                    write_colored_output("> ", YELLOW, end='')
                    prompt_name = input()
                    if prompt_name in prompt_names:
                        print('There is already a prompt with that name. Do you want to overwrite it?')
                        write_colored_output("> ", YELLOW, end='')
                        are_you_sure = input()
                        if are_you_sure != 'y':
                            print('Not saving prompt.')
                            break
                    save_prompt(prompt, prompt_name, get_data_dir() + '/prompts/')
                    break
            messages.append({"role": "system", "content": prompt})
            continue
        elif message == 'prompt list':
            print("Saved prompts:")
            list_saved_prompts()
            continue
        elif message == 'prompt load':
            if last_response != '':
                print('Are you sure you want to leave the current personality? y/n')
                write_colored_output("> ", YELLOW, end='')
                are_you_sure = input()
                if are_you_sure != 'y':
                    continue
                messages = []
            print("Select from saved prompts (enter desired number): ")
            list_saved_prompts()
            while True:
                write_colored_output("> ", YELLOW, end='')
                selected_prompt_n = input()
                if not selected_prompt_n.isdigit():
                    print("Must enter number of desired prompt.")
                    continue
                selected_prompt_name = prompt_names[int(selected_prompt_n) - 1]
                prompt = load_prompt(selected_prompt_name, get_data_dir() + '/prompts/')
                messages.append({"role": "system", "content": prompt})
                break
            continue

        append_user_message(message)

        collected_chunks = []
        collected_messages = []
        chunk_tokens = 0

        start_time = time.time()
        response = openai.ChatCompletion.create(
            model=DEFAULT_MODEL,
            messages=messages,
            temperature=0,
            stream=True)

        for chunk in response:

            chunk_time = time.time() - start_time  # calculate the time delay of the chunk
            collected_chunks.append(chunk)  # save the event response
            chunk_delta = json.loads(f"{chunk['choices'][0]['delta']}")

            chunk_tokens = 0

            if "role" in chunk_delta:
                continue
            elif "content" in chunk_delta:
                chunk_message = chunk_delta["content"]
                collected_messages.append(chunk_message)  # save the message
                chunk_tokens += 1
                print(chunk_message, end='', flush=True)
            last_response = ''.join(collected_messages)
        
        append_assistant_message(message)
        session_token_usage["completion_tokens"] += chunk_tokens
        print()

