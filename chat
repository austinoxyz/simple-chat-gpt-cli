#!/usr/bin/python3

# Refererence URL
# https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb

# Example of an OpenAI ChatCompletion request with stream=True
# https://platform.openai.com/docs/guides/chat': '

import os
import sys
import time
import json
import subprocess

import openai

model = 'gpt-3.5-turbo'
total_token_usage = { }

RED = '\033[31m'
GREEN = '\033[32m'
YELLOW = '\033[33m'
BLUE = '\033[34m'
RESET = '\033[0m'

def write_colored_output(output, color, end='\n'):
    sys.stdout.write(color + output + RESET + end)

def set_clipboard_text(text):
    p = subprocess.Popen(['xclip', '-selection', 'clipboard'], stdin=subprocess.PIPE)
    p.stdin.write(text.encode('utf-8'))
    p.stdin.close()
    p.wait()


def append_user_message(message):
    global messages
    messages.append({"role": "user", "content": message})

def append_assistant_message(message):
    global messages
    messages.append({"role": "assistant", "content": message})

def load_prompt_names(prompts_dir):
    return [filename[:-7] for filename in os.listdir(prompts_dir) if filename.endswith('.prompt')]


def load_config(config_file_name):
    try:
        json_raw = ''
        with open(config_file_name, 'r') as config_file:
            json_raw += config_file.read()
        config = json.loads(json_raw)
    except IOError:
        print(f"Couldn't read {config_file_name}. Wheres your config?")
        sys.exit(1)
    except JSONDecodeError:
        print(f"Malformed json in {config_file_name}:")
        import traceback
        print(traceback.format_exc())
    return config

def load_api_key(api_key_file_name):
    try:
        with open(api_key_file_name, 'r') as api_key_file:
            key = api_key_file.readline()
    except IOError:
        print(f"Couldn't read {api_key_file_name}. Check your config!")
        sys.exit(1)
    return key

def load_token_usage(token_usage_file_name):
    try:
        with open(token_usage_file_name, 'r') as token_usage_file:
            token_usage = json.loads(token_usage_file.readline())
    except IOError:
        print(f"Couldn't read {token_usage_file_name}. Check your config!")
        sys.exit(1)
    return token_usage

def account_token_usage(request_token_usage):
    pass


def save_prompt(prompt, prompt_name):
    prompt_file_name = prompt_name + '.prompt'
    print(f'Saving to {prompt_file_name}')
    try:
        with open(prompt_file_name, 'w') as prompt_file:
            prompt_file.write(prompt)
    except IOError:
        print(f"Couldn't write to {prompt_file_name}.")



config_file_name = 'config.json'
config = load_config(config_file_name)

openai.api_key_path = config["api_key_file"]

token_usage = load_token_usage(config["token_usage_file"])

prompt = "After being given a google search query, you will provide raw markdown that resembles the first 5 results. If provided a number, give the url of that search result."
prompt_names = load_prompt_names(config["prompts_dir"])

last_response = ''
session_token_usage = { "completion_tokens": 0, "prompt_tokens": 0, "total_tokens": 0 }

print('Welcome to gpt-3.5 cli')
print('type `exit` to exit')
while True:
    messages = []
    while True:
        write_colored_output("> ", YELLOW, end='')
        message = input()

        # TODO implement `save`, 
        # TODO implement `prompt new`, `prompt load` 
        # TODO implement `personality new`, `personality load` 
        if message == 'exit':
            account_token_usage(session_token_usage)
            sys.exit(0)
        elif message == 'clip':
            if last_response is None:
                print('Must provide an initial message before you can `clip`')
                continue
            set_clipboard_text(last_response)
            continue
        elif message == 'prompt new':
            if last_response != '':
                print('Are you sure you want to leave the current personality? y/n')
                write_colored_output("> ", YELLOW, end='')
                are_you_sure = input()
                if are_you_sure != 'y':
                    continue
                messages = []
            print('Enter your prompt: ')
            prompt = input()
            print('Would you like to save this prompt for future use?')
            are_you_sure = input()
            if are_you_sure == 'y':
                while True:
                    print('What would you like to name this prompt?')
                    prompt_name = input()
                    if prompt_name in prompt_names:
                        print('There is already a prompt with that name. Do you want to overwrite it?')
                        are_you_sure = input()
                        if are_you_sure != 'y':
                            print('Not saving prompt.')
                            break
                        save_prompt(prompt, prompt_name)
                    break
                

            messages.append({"role": "system", "content": prompt})

            continue

        append_user_message(message)

        collected_chunks = []
        collected_messages = []
        chunk_tokens = 0

        start_time = time.time()
        response = openai.ChatCompletion.create(
            model=model,
            messages=messages,
            temperature=0,
            stream=True)

        for chunk in response:

            chunk_time = time.time() - start_time  # calculate the time delay of the chunk
            collected_chunks.append(chunk)  # save the event response
            chunk_delta = json.loads(f"{chunk['choices'][0]['delta']}")

            chunk_tokens = 0

            if "role" in chunk_delta:
                continue
            elif "content" in chunk_delta:
                chunk_message = chunk_delta["content"]
                collected_messages.append(chunk_message)  # save the message
                chunk_tokens += 1
                print(chunk_message, end='', flush=True)
            last_response = ''.join(collected_messages)
        
        append_assistant_message(message)
        session_token_usage["completion_tokens"] += chunk_tokens
        print()

