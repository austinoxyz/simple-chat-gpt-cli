#!/usr/bin/python3

# Refererence URL
# https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb

# Example of an OpenAI ChatCompletion request with stream=True
# https://platform.openai.com/docs/guides/chat': '

import sys
import time
import json
import subprocess

import openai

model = 'gpt-3.5-turbo'
total_token_usage = { }


RED = '\033[31m'
GREEN = '\033[32m'
YELLOW = '\033[33m'
BLUE = '\033[34m'
RESET = '\033[0m'

def write_colored_output(output, color, end='\n'):
    sys.stdout.write(color + output + RESET + end)

def set_clipboard_text(text):
    p = subprocess.Popen(['xclip', '-selection', 'clipboard'], stdin=subprocess.PIPE)
    p.stdin.write(text.encode('utf-8'))
    p.stdin.close()
    p.wait()


def append_user_message(message):
    global messages
    messages.append({"role": "user", "content": message})

def append_assistant_message(message):
    global messages
    messages.append({"role": "assistant", "content": message})



def load_config(config_file_name):
    try:
        json_raw = ''
        with open(config_file_name, 'r') as config_file:
            json_raw += config_file.read()
        config = json.loads(json_raw)
    except IOError:
        print(f"Couldn't read {config_file_name}. Wheres your config?")
        sys.exit(1)
    except JSONDecodeError:
        print(f"Malformed json in {config_file_name}:")
        import traceback
        print(traceback.format_exc())
    return config

def load_api_key(api_key_file_name):
    try:
        with open(api_key_file_name, 'r') as api_key_file:
            key = api_key_file.readline()
    except IOError:
        print(f"Couldn't read {api_key_file_name}. Check your config!")
        sys.exit(1)
    return key

def load_token_usage(token_usage_file_name):
    try:
        with open(token_usage_file_name, 'r') as token_usage_file:
            token_usage = json.loads(token_usage_file.readline())
    except IOError:
        print(f"Couldn't read {token_usage_file_name}. Check your config!")
        sys.exit(1)
    return token_usage

def account_token_usage(request_token_usage):
    pass



config_file_name = 'config.json'
config = load_config(config_file_name)

openai.api_key_path = config["api_key_file"]

token_usage = load_token_usage(config["token_usage_file"])

prompt = "After being given a google search query, you will provide raw markdown that resembles the first 5 results. If provided a number, give the url of that search result."
messages = [{"role": "system", "content": prompt}]

last_response = ''
session_token_usage = { "completion_tokens": 0, "prompt_tokens": 0, "total_tokens": 0 }

print('Welcome to gpt-3.5 cli')
print('type `exit` to exit')
while True:
    write_colored_output("> ", YELLOW, end='')
    message = input()

    # TODO implement `save`, `personality new`, `personality load`, `clip`
    if message == 'exit':
        break
    elif message == 'clip':
        if last_response is None:
            print('Must provide an initial message before you can `clip`')
            continue
        set_clipboard_text(last_response)
        continue

    append_user_message(message)

    collected_chunks = []
    collected_messages = []
    chunk_tokens = 0

    start_time = time.time()
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=0,
        stream=True)

    for chunk in response:

        chunk_time = time.time() - start_time  # calculate the time delay of the chunk
        collected_chunks.append(chunk)  # save the event response
        chunk_delta = json.loads(f"{chunk['choices'][0]['delta']}")

        chunk_tokens = 0

        if "role" in chunk_delta:
            continue
        elif "content" in chunk_delta:
            chunk_message = chunk_delta["content"]
            collected_messages.append(chunk_message)  # save the message
            chunk_tokens += 1
            print(chunk_message, end='', flush=True)
        last_response = ''.join(collected_messages)
    
    append_assistant_message(message)
    session_token_usage["completion_tokens"] += chunk_tokens
    print()
account_token_usage(session_token_usage)

